{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XNPA_oTSYALx",
    "outputId": "1306f10d-4b2f-4191-cb4e-c7f83e4922fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\achma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\achma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengunduh dan Mengimpor Pustaka yang Diperlukan\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOGwKclZYijr"
   },
   "source": [
    "stopwords : untuk mengunduh daftar stop words dalam berbagai bahasa termasuk bahasa Inggris, yang disediakan oleh NLTK.\n",
    "\n",
    "punkt : untuk mengunduh pustaka tokenisasi yang memungkinkan kita memecah kalimat menjadji kata-kata (dikenal sebagai tokenisasi).\n",
    "\n",
    "Dalam EDA, ini merupakan proses cleaning.\n",
    "kenapa? karena dalam IR ini bermaksud membersihkan kata.\n",
    "Dan di IR ini berfokus untuk pengolahan kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WPcwgov9YRR-"
   },
   "outputs": [],
   "source": [
    "# Mengimpor modul stopwords dan word_tokenize dari NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypiMwx-WZR_6"
   },
   "source": [
    "corpus : untuk mengimpor modul stopwords .. yang berisi daftar kata-kata umum dalam berbagai bahasa yang bisa kita ..\n",
    "\n",
    "tokenize : untuk mengimpor fungsi word_tokenize yang digunakan untuk membagi kalimat menjadi kata-kata (token).\n",
    "\n",
    "mengimpor >> mendatangkan\n",
    "jadi pada tahapan ini kita memanggil kembali library yang sebelumnya sudah di instal sebelumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7A9aUKhDZQep"
   },
   "outputs": [],
   "source": [
    "# Contoh Kalimat yang Akan Difilter\n",
    "worf_quote = \"sir, I protest. I am not a merry man!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFX3VfmUaQsM",
    "outputId": "8beed646-7e2a-4ca2-f6a5-5406ca8d3442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sir', ',', 'I', 'protest', '.', 'I', 'am', 'not', 'a', 'merry', 'man', '!']\n"
     ]
    }
   ],
   "source": [
    "# Tokenisasi Kalimat\n",
    "words_in_quote = word_tokenize (worf_quote)\n",
    "print (words_in_quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hFDnGNkbO0w"
   },
   "source": [
    "1. fungsi word_tokenize adalah digunakan untuk membagi kalimat di dalam worf_quote menjadi kata-kata terpisah (tokens). Hasil tokenisasi akan mencakup tanda baca, sehingga kita bisa melihat seluruh elemen yang ada di dalam kelimat.\n",
    "2. Print tentu saya untuk menampilkan hasil tokenisasi seperti diatas\n",
    "\n",
    "note:\n",
    "pada case diatas, setiap 1 space maka terhitung kata. juga termasuk titik dan koma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JpOCcej3bkgO"
   },
   "outputs": [],
   "source": [
    "# Menentukan Stop Words Bahasa Inggris\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3s04f-9vcX2S"
   },
   "source": [
    "1. maksud dari codingan diatas berfungsi untuk memuat stop words untuk bahasa inggris.\n",
    "2. set(...) mengubah daftar stop words menjadi set, yang memungkinkan operasi pencari kata menjadi lebih cepat dan efisien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCai3GiObncG",
    "outputId": "57977db5-c23a-470b-d7ef-4ffd271e9647"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sir', ',', 'protest', '.', 'merry', 'man', '!']\n"
     ]
    }
   ],
   "source": [
    "# Memfilter Stop Words dari Teks\n",
    "filtered_list = [word for word in words_in_quote if word.casefold() not in stop_words]\n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko9uHUA-dQMK"
   },
   "source": [
    "1. [...] adalah bentuk list comprehension. Kode ini mengulang setiap word (kata) dalam words_in_quote. Jika kata tersebut tidak termasuk dalam stop_words, maka akan dimasukkan ke dalam filtered_list.\n",
    "2. word.casefold() : merupakan metode casefold mengubah kata menjadi huruf kecil untuk memastikan pencarian yang tidak sensitif terhadap huruf besar dan kecil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TTMCBksqbnoU"
   },
   "outputs": [],
   "source": [
    "# Stemming\n",
    "# Mengimpor modul porterstemmer dari NLTK\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4som_4l3gMmp"
   },
   "source": [
    "Mengimpor porterstemmer dari modul nltk.stem. Algoritma Porter Stemmer akan mengubah kata menjadi bentuk dasarnya berdasarkan aturan tertentu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q1Qgtk7Obn0W"
   },
   "outputs": [],
   "source": [
    "# Membuat objek porterstemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Tnh4WLrgdSp"
   },
   "source": [
    "Untuk membuat sebuah objek bernama stemmer yang menggunakan aturan stemming dari Porter Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YwShLXDPboBA"
   },
   "outputs": [],
   "source": [
    "# Menyiapkan Kalimat untuk Proses Stemming\n",
    "string_for_stemming =\"\"\"\n",
    "The crew of the USS Discovery discovered many discoveries.\n",
    "Discovering is what explores do.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2m89clUcg5Iq"
   },
   "source": [
    "Pada variabel ini menyimpan teks yang akan diolah menggunakan stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iqCusJlgjzf",
    "outputId": "b234f7b9-a1d9-4a5d-a47c-7b6739700702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'crew', 'of', 'the', 'USS', 'Discovery', 'discovered', 'many', 'discoveries', '.', 'Discovering', 'is', 'what', 'explores', 'do', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenisasi Teks\n",
    "words = word_tokenize(string_for_stemming)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAJtTE1GhJNP"
   },
   "source": [
    "word = ...dst : Menggunakan word_tokenize untuk memisahkan setiap kata dalam string_for_stemming.\n",
    "print : untuk menampilkan daftar kata yanng dihasilkan dari tokenisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hEsCL3kgkAS",
    "outputId": "108f74ff-58e8-41c0-d2b9-e02bc9818f54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'crew', 'of', 'the', 'uss', 'discoveri', 'discov', 'mani', 'discoveri', '.', 'discov', 'is', 'what', 'explor', 'do', '.']\n"
     ]
    }
   ],
   "source": [
    "# Menerapkan stemming pada setiap kata\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GmezkMKiB7x"
   },
   "source": [
    "1. [...dst] Merupakan bentuk lain dari list comprehension untuk melakukan stemming pada setiap kata dalam words. Hasil dari stemming akan dimasukkan dalam daftar stemmed_words.\n",
    "2. stemmer.stem(word) : merupakan fungsi step menerapkan algoritma Porter Stemmer pada setiap word, mengubah kata tersebut ke bentuk dasar yang dihasilkan oleh aturan stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0aVvDlKo1De"
   },
   "source": [
    "#Latihan 2 - Pekan 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVjPTXJ-Yyty"
   },
   "source": [
    "Tugas 1 : Memfilter Stop Words pada Teks Berita\n",
    "\n",
    "Tugas 2 : Mengaplikasikan Stemming pada Artikel Berbahasa Indonesia\n",
    "\n",
    "Tugas 3 : Menggabungkan Stop Words dan Stemming\n",
    "\n",
    "Tugas 4 : Membangun Fungsi Penghapus Stop Words dan Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39zT2ajOZj6G"
   },
   "source": [
    "**Tugas 1 : Memfilter Stop Words pada Teks Berita**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_oxfDHnrgkLF"
   },
   "outputs": [],
   "source": [
    "# # Mengunduh dan Mengimpor Pustaka yang Diperlukan\n",
    "# import nltk\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZZhgbtCmboNT"
   },
   "outputs": [],
   "source": [
    "# # Mengimpor modul stopwords dan word_tokenize dari NLTK\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B22QD5GcZzOV"
   },
   "outputs": [],
   "source": [
    "# Teks Berita dalam Bahasa Indonesia tentang judi online\n",
    "news_text = \"\"\"\n",
    "Sejumlah pihak menilai penangkapan belasan pegawai Kementerian Komunikasi dai Digital (Komdigi) tidak akan memberantas judi online, kecuali aparat Indonesia mampu menyentuh para tokoh utama kejahatan tersebut.\n",
    "Jumlah pegawai Komdigi yang ditangkap atas tuduhan melindungi situs judi online terus bertambah hingga 16 orang.\n",
    "Walau pemerintah menyebut penangkapan itu merupakan upaya memberantas judi online, sebagian kalangan yakin persoalan menahun ini tak akan bisa tuntas jika penindakan tidak menyentuh para bandar dan pengendali utamanya.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3w3PSsfGaHH1",
    "outputId": "3beb00c7-e6cb-476e-d446-0c8ddc0a21d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Tokenisasi:\n",
      " ['Sejumlah', 'pihak', 'menilai', 'penangkapan', 'belasan', 'pegawai', 'Kementerian', 'Komunikasi', 'dai', 'Digital', '(', 'Komdigi', ')', 'tidak', 'akan', 'memberantas', 'judi', 'online', ',', 'kecuali', 'aparat', 'Indonesia', 'mampu', 'menyentuh', 'para', 'tokoh', 'utama', 'kejahatan', 'tersebut', '.', 'Jumlah', 'pegawai', 'Komdigi', 'yang', 'ditangkap', 'atas', 'tuduhan', 'melindungi', 'situs', 'judi', 'online', 'terus', 'bertambah', 'hingga', '16', 'orang', '.', 'Walau', 'pemerintah', 'menyebut', 'penangkapan', 'itu', 'merupakan', 'upaya', 'memberantas', 'judi', 'online', ',', 'sebagian', 'kalangan', 'yakin', 'persoalan', 'menahun', 'ini', 'tak', 'akan', 'bisa', 'tuntas', 'jika', 'penindakan', 'tidak', 'menyentuh', 'para', 'bandar', 'dan', 'pengendali', 'utamanya', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenisasi Teks\n",
    "words_in_news = word_tokenize(news_text)\n",
    "print(\"Hasil Tokenisasi:\\n\", words_in_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jH-9Zq3laNkA"
   },
   "outputs": [],
   "source": [
    "# Menentukan Stop Words Bahasa Indonesia\n",
    "stop_words_id = set(stopwords.words(\"indonesian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwKWnRshaaVX",
    "outputId": "0c284885-343a-4bf8-a66a-bab1bb31b8eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teks Setelah Difilter:\n",
      " ['menilai', 'penangkapan', 'belasan', 'pegawai', 'Kementerian', 'Komunikasi', 'dai', 'Digital', '(', 'Komdigi', ')', 'memberantas', 'judi', 'online', ',', 'kecuali', 'aparat', 'Indonesia', 'menyentuh', 'tokoh', 'utama', 'kejahatan', '.', 'pegawai', 'Komdigi', 'ditangkap', 'tuduhan', 'melindungi', 'situs', 'judi', 'online', 'bertambah', '16', 'orang', '.', 'pemerintah', 'menyebut', 'penangkapan', 'upaya', 'memberantas', 'judi', 'online', ',', 'kalangan', 'menahun', 'tuntas', 'penindakan', 'menyentuh', 'bandar', 'pengendali', 'utamanya', '.']\n"
     ]
    }
   ],
   "source": [
    "# Memfilter Stop Words\n",
    "filtered_news = [word for word in words_in_news if word.casefold() not in stop_words_id]\n",
    "print(\"Teks Setelah Difilter:\\n\", filtered_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0i_Tw7aUalbG"
   },
   "source": [
    "**Tugas 2 : Mengaplikasikan Stemming pada Artikel Berbahasa Indonesia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WSAsu6Hyao63"
   },
   "outputs": [],
   "source": [
    "# # Mengunduh dan Mengimpor Pustaka yang Diperlukan\n",
    "# import nltk\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "s-Lpyrxoaqjf"
   },
   "outputs": [],
   "source": [
    "# # Mengimpor PorterStemmer dari NLTK\n",
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vOOORl6JbKzZ"
   },
   "outputs": [],
   "source": [
    "# Membuat objek PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TnwZxBgFbL7x"
   },
   "outputs": [],
   "source": [
    "# Artikel Berbahasa Indonesia tentang Programming\n",
    "article_text = \"\"\"\n",
    "Apa yang terlintas di benakmu ketika mendengar kata “programming”? Kodingkah? Atau perkomputeran? Masih keliru nih. Hemm, alangkah baiknya kita dimulai dari yang dasar-dasar dulu ya. Programming yaitu program.\n",
    "Seperti apa itu program? Program merupakan suatu urutan logika dengan input dan output tertentu. Program juga dapat berupa kumpulan perintah agar komputer dapat berfungsi secara optimal sesuai dengan kemauan. Program yang disatukan dengan sistem disebut aplikasi, seperti aplikasi web, maupun android.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSpAH4ixbpkJ",
    "outputId": "7a1f99c4-a363-4b13-ef76-3d38dfd417f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Tokenisasi:\n",
      " ['Apa', 'yang', 'terlintas', 'di', 'benakmu', 'ketika', 'mendengar', 'kata', '“', 'programming', '”', '?', 'Kodingkah', '?', 'Atau', 'perkomputeran', '?', 'Masih', 'keliru', 'nih', '.', 'Hemm', ',', 'alangkah', 'baiknya', 'kita', 'dimulai', 'dari', 'yang', 'dasar-dasar', 'dulu', 'ya', '.', 'Programming', 'yaitu', 'program', '.', 'Seperti', 'apa', 'itu', 'program', '?', 'Program', 'merupakan', 'suatu', 'urutan', 'logika', 'dengan', 'input', 'dan', 'output', 'tertentu', '.', 'Program', 'juga', 'dapat', 'berupa', 'kumpulan', 'perintah', 'agar', 'komputer', 'dapat', 'berfungsi', 'secara', 'optimal', 'sesuai', 'dengan', 'kemauan', '.', 'Program', 'yang', 'disatukan', 'dengan', 'sistem', 'disebut', 'aplikasi', ',', 'seperti', 'aplikasi', 'web', ',', 'maupun', 'android', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenisasi Teks\n",
    "words_in_article = word_tokenize(article_text)\n",
    "print(\"Hasil Tokenisasi:\\n\", words_in_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z69lrpsmbrmR",
    "outputId": "b6a4ac61-6592-4a93-d1b3-a69b1495d54e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Stemming:\n",
      " ['apa', 'yang', 'terlinta', 'di', 'benakmu', 'ketika', 'mendengar', 'kata', '“', 'program', '”', '?', 'kodingkah', '?', 'atau', 'perkomputeran', '?', 'masih', 'keliru', 'nih', '.', 'hemm', ',', 'alangkah', 'baiknya', 'kita', 'dimulai', 'dari', 'yang', 'dasar-dasar', 'dulu', 'ya', '.', 'program', 'yaitu', 'program', '.', 'seperti', 'apa', 'itu', 'program', '?', 'program', 'merupakan', 'suatu', 'urutan', 'logika', 'dengan', 'input', 'dan', 'output', 'tertentu', '.', 'program', 'juga', 'dapat', 'berupa', 'kumpulan', 'perintah', 'agar', 'komput', 'dapat', 'berfungsi', 'secara', 'optim', 'sesuai', 'dengan', 'kemauan', '.', 'program', 'yang', 'disatukan', 'dengan', 'sistem', 'disebut', 'aplikasi', ',', 'seperti', 'aplikasi', 'web', ',', 'maupun', 'android', '.']\n"
     ]
    }
   ],
   "source": [
    "# Menerapkan Stemming pada Setiap Kata Menggunakan PorterStemmer\n",
    "stemmed_article = [stemmer.stem(word) for word in words_in_article]\n",
    "print(\"Hasil Stemming:\\n\", stemmed_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQ41a9FTdrls"
   },
   "source": [
    "**Tugas 3 : Menggabungkan Stop Words dan Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NszHpNkbkaDy"
   },
   "outputs": [],
   "source": [
    "# # Mengunduh dan Mengimpor Pustaka yang Diperlukan\n",
    "# import nltk\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "od73m1uSkbJT"
   },
   "outputs": [],
   "source": [
    "# # Mengimpor modul stopwords dan word_tokenize dari NLTK\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "0cYh9rtrbuV7"
   },
   "outputs": [],
   "source": [
    "# Teks Paragraf\n",
    "text_paragraph = \"Python merupakan bahasa pemrograman komputer yang biasa dipakai untuk membangun situs, software/aplikasi, mengotomatiskan tugas dan melakukan analisis data. Bahasa pemrograman ini termasuk bahasa tujuan umum. Artinya, ia bisa digunakan untuk membuat berbagai program berbeda, bukan khusus untuk masalah tertentu saja.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mRUtCE35dxyx"
   },
   "outputs": [],
   "source": [
    "# Tokenisasi Teks\n",
    "words_in_paragraph = word_tokenize(text_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "f18H2Ivue_-p"
   },
   "outputs": [],
   "source": [
    "# Menghapus stop words dari teks paragraf\n",
    "filtered_words = [word for word in words_in_paragraph if word.casefold() not in stop_words_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKmYDFFzfBTq",
    "outputId": "0bb2d39f-6e0e-4d48-9548-e398bf571ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Filter dan Stemming Text:\n",
      " ['python', 'bahasa', 'pemrograman', 'komput', 'dipakai', 'membangun', 'situ', ',', 'software/aplikasi', ',', 'mengotomatiskan', 'tuga', 'analisi', 'data', '.', 'bahasa', 'pemrograman', 'bahasa', 'tujuan', '.', ',', 'program', 'berbeda', ',', 'khusu', '.']\n"
     ]
    }
   ],
   "source": [
    "# Melakukan stemming pada kata-kata yang teratas\n",
    "stemmed_result = [stemmer.stem(word) for word in filtered_words]\n",
    "print(\"Hasil Filter dan Stemming Text:\\n\", stemmed_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "041XgsxflaJ2"
   },
   "source": [
    "**Tugas 4 : Membangun Fungsi Penghapus Stop Words dan Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfc9EAyAlYFy",
    "outputId": "983e84c9-d07f-47f7-8cb4-eaee263cc2ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Preprocessing:\n",
      " ['bahasa', 'pemrograman', 'tool', 'wajib', 'dikuasai', 'programm', '.', 'bahasa', 'program', 'pemrograman', 'sekumpulan', 'instruksi', 'komput', 'tugas-tuga', 'menyelesaikan', '.']\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk Menghapus Stop Words dan Melakukan Stemming\n",
    "def process_text(text):\n",
    "    # Tokenisasi\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Menentukan Stop Words Berdasarkan Bahasa\n",
    "    filtered_words = [word for word in words if word.casefold() not in stop_words_id]\n",
    "\n",
    "    # Proses Penghapusan Stop Words dan Stemming\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "    return stemmed_words\n",
    "\n",
    "# Contoh Penggunaan Fungsi pada Artikel Berbahasa Indonesia\n",
    "sample_text = \"\"\"\n",
    "Bahasa pemrograman adalah tool yang wajib dikuasai oleh para programmer. Bahasa program atau pemrograman sendiri adalah sekumpulan instruksi yang diberikan kepada komputer agar bisa melakukan tugas-tugas tertentu dalam menyelesaikan sebuah masalah.\n",
    "\"\"\"\n",
    "result = process_text(sample_text)\n",
    "print(\"Hasil Preprocessing:\\n\", result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
